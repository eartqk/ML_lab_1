# Лабораторная по машинному обучению №1

## Задание
1) Реализовать следующие алгоритмы машинного обучения: Linear/ 
Logistic Regression, SVM, KNN, Naive Bayes в отдельных классах 
2) Данные классы должны наследоваться от BaseEstimator
и ClassifierMixin, иметь методы fit и predict
3) Вы должны организовать весь процесс предобработки, обучения и 
тестирования с помощью Pipeline
4) Вы должны настроить гиперпараметры моделей с помощью кросс 
валидации (GridSearchCV, RandomSearchCV) вывести и сохранить эти 
гиперпараметры в файл, вместе с обученными моделями
5) Проделать аналогично с коробочными решениями
6) Для каждой модели получить оценки метрик: Confusion 
Matrix, Accuracy, Recall, Precision, ROC_AUC curve
7) Проанализировать полученные результаты и сделать выводы о 
применимости моделей
8) Загрузить полученные гиперпараметры модели и обученные модели в 
формате pickle на гит вместе с jupyter notebook ваших экспериментов

## Обработка данных

Для начала необходимо подготовить данные для обучения. Категориальные
признаи закодируем с помощью One Hot Encoding, количественные признаки 
приведем к стандартному нормальному распределению (среднее = 0, 
дисперсия = 1).
Затем посплитим данные на трейн и тест.

Сведения, которые мы знаем о каждом ученике:

1. type_school - тип школы, в которую ходит ученик
2. school_accreditation - аккредитация школы (A / B)
3. gender - пол ученика
4. interest - заинтересованность в учебе
5. residence - место проживания (город / пригород)
6. parent_age - возраст родителей
7. parent_salary - зарплата родителей
8. house_area - площадь родительского дома
9. average_grades - средний балл (от 0 до 100)
10. parent_was_in_college - учились ли родители в колледже
11. in_college - пошел ли ученик в колледж - таргет

## Подсчет метрик

Для оценивания качества моделей будем использовать метрики:

- Accuracy
- Precision
- Recall

и будем строить матрицу неточностей.

Вычислять все это мы будем с помощью функций Sklearn.

## Выводы

В этой работе я релизовал 4 алгоритма машинного обучения: КНН, 
логистическую регрессию, СВМ и наивного Байеса. Каждую из этих моделей 
я обучил, провалидировал и сравнил с реализацией из Sklearn.

Результаты всех моих моделей совпали с результатами моделей из Sklearn (ну 
или незначительно отличаются из-за разных алгоритмов, рандом сидов и т.д.).

Все модели показали примерно одинаковый результат. Лучше всего отработал 
KNN:

- Accuracy: 0.88 
- Precision: 0.9175257731958762 
- Recall: 0.8476190476190476 

Но остальные алгоритмы были ненамного хуже. Возможно, если бы в качестве 
порога вероятности мы бы использовали не 0.5, а какое-то другое число, то 
результаты были бы чуть-чуть получше.